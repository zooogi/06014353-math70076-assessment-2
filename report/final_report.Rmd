---
title: 'Replication Report: Empathy, Mental Health, and Burnout in Medical Students'
author: "CID:06014353"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
    number_sections: true            
    toc: true                        
    toc_depth: 2                      
    fig_caption: true                
    keep_tex: true                   
    pandoc_args: ["--variable=fontsize:11pt"]  
    df_print: paged
knitr:
  root.dir: ..
  opts_chunk:
    echo: false      
    message: false  
    warning: false   
bibliography: ["report/references.bib"]
link-citations: true
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage[table]{xcolor}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{fontspec}
---

```{r setup, include=FALSE,tidy=TRUE}
knitr::opts_chunk$set(echo = FALSE)
```
```{r load packages, include=FALSE}
library(here)
library(dplyr)
library(knitr)
library(kableExtra)
library(stringr)
library(tidyverse)
library(ggplot2)
library(stringr)
library(forcats)
```
```{r load table and data, include=FALSE}
final_table1 <- read_csv(here("figures", "table1_descriptive_stats.csv"),show_col_types = FALSE)
final_table2 <- read_csv(here("figures", "table2_replication.csv"),show_col_types = FALSE)
final_table3 <- read_csv(here("figures", "table3_replication.csv"),show_col_types = FALSE)
final_eta <- read_csv(here("figures", "cesd_prevalence_by_year.csv"))
df_raw <- read_csv("data/raw/Data Carrard et al. 2022 MedTeach.csv",show_col_types = FALSE)
df_cesd<- readRDS("data/processed/derived_data.rds")
df_clean <- readRDS("data/processed/cleaned_data.rds")
```

# Background and Aim
This report replicates a study by Carrard et al. (2021) published in *Medical Teacher* (@Carrard02122022). The study examines how medical students’ empathy (cognitive, affective, behavioral) relates to their mental health (depression, anxiety) and burnout. It uses cross-sectional survey data from 886 students (years 1–6) at a Swiss medical school. All measures were collected via self-report questionnaires, and linear regression was used to analyze the associations. This replication uses R and the original dataset publicly available on Zenodo (https://zenodo.org/records/5702895#.Y8OraNJBwUE) to fully reproduce the key results (Table 2 and Table 3) and evaluate the study’s reproducibility and robustness.

# Methods
The data used in this replication are from the original study’s publicly released questionnaire dataset on Zenodo, including self-reported data from 886 Swiss medical students. It covers empathy (JSPE-S, QCAE, AMSP, GERT-S) across cognitive, affective, and behavioral dimensions, mental health (CES-D, STAI), and burnout (MBI). Data preprocessing strictly followed the original setup, excluding non-binary individuals (n = 5). Gender and year were converted to factors for regression modeling. A binary “depression risk” variable was created based on CES-D gender-specific cut-offs (male $\ge 16$, female $\ge 21$).

The analysis has two parts: (1) build 10 linear models using year and gender as predictors for mental health and burnout outcomes; (2) build 25 models to test five empathy dimensions predicting five outcomes. All models were built using `lm()`, with formulas generated by `reformulate()` for batch modeling.

To match the original results, standardized $\beta$ coefficients were computed using `parameters::standardize_parameters()` with `method = "basic"`:
\[
\beta^* = \hat{\beta} \cdot \frac{\text{SD}(x)}{\text{SD}(y)}
\]
Partial $\eta^2$ (`effectsize::eta_squared()`), standard errors, F-statistics, and R² were also extracted to fully reproduce the original results.

As supplementary analyses, two descriptive tests from the original Results were replicated: (1) chi-square test comparing sample gender distribution with the school population to test representativeness (The null hypothesis: No difference between sample and population gender distribution); (2) compute proportion at clinical depression risk based on CES-D cut-offs to verify key reported ratios.

# Results
The table below shows the descriptive statistics from this replication. All variables align closely with those in the original Table 1, confirming correct data loading and processing. Due to the large number of variables, only key demographic and mental health variables are shown here; the full list is in the appendix (Table\@ref(tab:table2)) or supplementary materials. I also replicated a supplementary analysis from the original: a chi-square test comparing the sample’s gender distribution with the overall medical school population. The result ($\chi^2 = 1.24$, df = 1, $p = 0.265$) was not significant, consistent with the original, supporting sample representativeness.
```{r}
final_table1_clean <- final_table1 %>%
  filter(!str_starts(Variable, "glang")) %>%
  filter(!str_starts(Variable, "Consulted psy last year")) %>%
  filter(!str_starts(Variable, "Has")) %>%
  filter(!str_starts(Variable, "Mother tongue")) %>%
  filter(
    !Variable %in% c(
      "health",
      "stud_h",
      "age"
      )) %>%
  
  mutate(
    `Mean (SD)` = ifelse(is.na(`Mean (SD)`), "-", `Mean (SD)`),
    Percent      = ifelse(is.na(Percent), "-", Percent)
  ) %>%
  
  mutate(
    Variable = case_when(
      Variable == "stai_t"  ~ "Anxiety", 
      Variable == "cesd" ~ "Depressive symptoms",
      Variable == "amsp"  ~ "AMSP",
      Variable == "erec_mean"  ~ "GERT-S", 
      Variable == "mbi_cy" ~ "Cynicism",
      Variable == "mbi_ea"  ~ "Academic efficacy",
      Variable == "mbi_ex"  ~ "Emotional exhaustion", 
      Variable == "qcae_aff" ~ "QCAE affective",
      Variable == "qcae_cog"  ~ "QCAE cognitive",
      Variable == "jspe"  ~ "JSPE-S",
      TRUE                     ~ Variable
    )
  )
```
```{r}
final_table1_clean %>%
  kable(
    caption = "The results of reproducing descriptive statistics (N = 886)",
    col.names = c("Variable", "Mean (SD)", "Percent"),
    digits = c(NA, 2, 2)
  ) %>%
  kable_styling(latex_options = c("H", "scale_down"), font_size = 11,full_width = FALSE)

```
To replicate Table 2 from the original paper, we ran linear regressions on five mental health and burnout outcomes (CES-D, STAI, three MBI dimensions) and five empathy measures (JSPE-S, QCAE, AMSP, GERT-S), using standardized $\beta$ to assess the effects of year (vs. B1) and gender (female vs. male). Full results are in the appendix (Table\@ref(tab:table3)); this section shows a visualization of the replication.

The plot shows most mental health outcomes (e.g., depressive symptoms, anxiety, emotional exhaustion) decrease with higher year, suggesting improved mental states. Female students have positive βs for depression, anxiety, and emotional exhaustion, indicating more negative emotions. Females also score higher on nearly all empathy dimensions, especially QCAE affective empathy ($\beta = 0.37$*** ).

These results match Table 2 in the original study, supporting the conclusion that higher-year students report better mental health and females show higher empathy. The regression was successfully replicated.
```{r fig:beta-bar, echo=FALSE, message=FALSE, fig.width=14, fig.height=10,warning=FALSE,out.extra='keepaspectratio=true, width=\\textwidth', fig.cap="Standardized regression coefficients (β) by outcome, with significance stars"}

# 1) Prepare plotting data: extract numeric β and keep full 'β' string for labels
plot_df <- final_table2 %>%
  mutate(
    beta_num = as.numeric(str_extract(β, "-?\\d+\\.\\d+")),   # numeric part of β
    label    = β,                                             # full β+stars
    term     = factor(term, levels = c("yearB2","yearB3",
                                       "yearM1","yearM2",
                                       "yearM3","sexFemale")))%>%
  mutate(
    outcome = case_when(
      outcome == "stai_t"  ~ "Anxiety", 
      outcome == "cesd" ~ "Depressive symptoms",
      outcome == "amsp"  ~ "AMSP",
      outcome == "erec_mean"  ~ "GERT-S", 
      outcome == "mbi_cy" ~ "Cynicism",
      outcome == "mbi_ea"  ~ "Academic efficacy",
      outcome == "mbi_ex"  ~ "Emotional exhaustion", 
      outcome == "qcae_aff" ~ "QCAE affective",
      outcome == "qcae_cog"  ~ "QCAE cognitive",
      outcome == "jspe"  ~ "JSPE-S",
      TRUE                     ~ outcome
    ))

# 2) Draw bar plot, faceting by outcome
ggplot(plot_df, aes(x = term, y = beta_num)) +
  geom_col(fill = "steelblue") +
  geom_text(aes(label = label),
            vjust = ifelse(plot_df$beta_num >= 0, -0.3,  1.3),
            size = 3) +
  facet_wrap(~ outcome, scales = "free_x", nrow = 2, strip.position = "top") +
  labs(
    x        = NULL,
    y        = "Standardized β",
    title    = "Standardized Regression Coefficients by Outcome",
    subtitle = "Bar height = β value; stars indicate significance (* p<0.05, ** p<0.01, *** p<0.001)"
  ) +
  theme_bw(base_size = 12) +
  theme(
    axis.text.x      = element_text(angle = 45, hjust = 1),
    strip.background = element_rect(fill = "grey95"),
    strip.text       = element_text(face = "bold")
  )

# Save
ggsave("figures/beta_barplot_by_outcome.pdf", width = 14, height = 10)
```
To replicate Table 3 of the original study, we ran linear regressions for five mental health and burnout outcomes (CES-D, STAI, three MBI dimensions), using five empathy measures (JSPE-S, QCAE cognitive, QCAE affective, AMSP, GERT-S) as predictors. Year and gender were controlled, following the original setup.

The figure below shows standardized β and effect sizes (η²). Color indicates direction and size of $\beta$; text shows $\beta$ values with significance (* $p < .05$, ** $p < .01$, *** $p < .001$).

Results clearly replicate key findings:  
1.QCAE affective empathy is significantly related to all outcomes, with positive $\beta$s—students with higher affective empathy report more problems, though effects are small ($\eta^2 < .05$).  
2.AMSP behavioral empathy predicts less depression, anxiety, and higher academic efficacy, with slightly stronger effects (max $\eta^2 = .05$).  
3.JSPE-S and QCAE cognitive empathy link to lower anxiety and better efficacy, but effects are weaker.  
4.GERT-S shows no significant relation with any outcome.

Full regression results (SEs, F, R²) are in the appendix (Table\@ref(tab:table4)).
```{r heatmap-beta-eta2, echo=FALSE, fig.cap="Heatmap of standardized β (top) and η² (bottom) for the empathy–outcome regressions", fig.height=10, fig.width=7}
plot_df3 <- final_table3 %>%
  rename(beta = estimate) %>%
  mutate(
    outcome = factor(outcome,
      levels = c("cesd", "stai_t", "mbi_ex", "mbi_cy", "mbi_ea"),
      labels = c("Depressive\nsymptoms",
                 "Anxiety",
                 "Emotional\nexhaustion",
                 "Cynicism",
                 "Academic\nefficacy")
    ),
    empathy = factor(empathy,
      levels = c("jspe", "qcae_cog", "qcae_aff", "amsp", "erec_mean"),
      labels = c("JSPE-S",
                 "QCAE-Cognitive",
                 "QCAE-Affective",
                 "AMSP",
                 "GERT-S")
    )
  ) %>%
  select(empathy, outcome, beta, p_stars, eta2) %>%
  pivot_longer(
    cols = c(beta, eta2),
    names_to  = "metric",
    values_to = "value"
  ) %>%
  mutate(
    label = case_when(
      metric == "beta" ~ sprintf("%0.2f%s", value, ifelse(is.na(p_stars),"",p_stars)),
      metric == "eta2" ~ sprintf("%0.2f", value)
    ),
    metric = factor(metric, levels = c("beta", "eta2"),
      labels = c("Standardized β", "η²")
    )
  )

ggplot(plot_df3, aes(x = outcome, y = empathy, fill = value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = label), size = 3) +
  scale_fill_gradient2(
    name = NULL,
    low  = "firebrick", mid = "white", high = "steelblue",
    midpoint = 0
  ) +
  facet_wrap(~ metric, ncol = 1, scales = "free") +
  labs(
    x = NULL, y = NULL
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position   = "bottom",
    strip.text        = element_text(face = "bold", size = 12, margin=margin(4,0,4,0)),
    axis.text.x       = element_text(angle = 0, vjust = 0.5),
    panel.grid.major  = element_blank(),
    panel.grid.minor  = element_blank()
  )
# Save
ggsave("figures/table3_heatplot_beta_eta.pdf", width = 7, height = 10)
```
To replicate the descriptive analysis of CES-D depression risk in the original study, we classified the sample using gender-specific cut-offs (male \(\ge 16\), female \(\ge 21\)). About 40.98% of students in the replication sample are at clinical depression risk, close to the 40.18% reported in the original. A breakdown by year shows a general decline in risk across years, closely matching the original trend. The table below compares depression risk proportions by year:
```{r}
# Original reported percentages from the paper
original_pct <- c(51.02, 45.93, 39.16, 34.96, 33.07, 24.78)
year_labels <- c("B1", "B2", "B3", "M1", "M2", "M3")

# Assuming final_eta is already available
compare_cesd <- final_eta %>%
  select(year, positive_pct) %>%
  mutate(
    `Original (%)` = original_pct,
    `Difference (%)` = round(positive_pct - original_pct, 2)
  ) %>%
  rename(`Year` = year, `Reproduced (%)` = positive_pct)

# Save
write_csv(compare_cesd, "figures/table_compare_cesd.csv")

# Display table
kable(compare_cesd,
      caption = "Comparison of CES-D clinical risk percentages by year (Reproduction vs. Original study)",
      align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position"),
                full_width = FALSE,
                position = "center")

```
# Discussion and Improvement suggestions
The replication process in this study went smoothly overall, thanks to the original paper’s detailed model descriptions, data access, and preprocessing steps, showing good reproducibility and research transparency. Although I used a different analysis tool (R instead of Stata), I was still able to successfully replicate the key regression results by following the publicly available data and methods, demonstrating the robustness of the original findings. This kind of cross-platform reproducibility is valuable in medical education research, increasing confidence in future intervention design and practical application.

Several key technical points emerged during the replication. For example, when fitting initial linear models with unstandardized data, the resulting $\beta$ coefficients differed from the original, although effect sizes ($\eta^2$) and F-values remained consistent. Upon further review, I confirmed that the original study used standardized β coefficients. I therefore applied `parameters::standardize_parameters(method = "basic")` in R to standardize the results. This method does not transform the data directly but uses the following formula to adjust coefficients based on the ratio of standard deviations:
\[
\beta^* = \hat{\beta} \cdot \frac{\text{SD}(x)}{\text{SD}(y)}
\]
This approach is logically equivalent to Stata’s `, beta` option. After standardization, the β values matched the original exactly, confirming the authors’ method and highlighting the importance of coefficient definitions in cross-platform replication.

For the CES-D positive rate (depression risk), I followed the gender-specific cut-offs noted in the paper (16 for males, 21 for females), and tested both “\(\ge\)” and “\(>\)” thresholds. In both cases, the calculated rate differed from the original by about 1%, though the trend was fully consistent. I suspect this difference may stem from how the authors handled scores at the cut-off (exactly 16 or 21), which was not explained in the paper. One possibility is that decisions were made based on clinical judgment or questionnaire logic; another is that they used adjusted or standardized scores (e.g., Z-scores, T-scores, scale scores, or totals excluding some items) rather than raw CES-D totals. As the paper lacks detail, such differences likely reflect unobservable decisions rather than replication error.

Building on the replication, I also optimized the result presentation by adding visual outputs. Compared to tables alone, bar plots and heatmaps more clearly show the direction and significance of standardized β coefficients, and allow more efficient comparison across models. This improves readability and communication, aligning with current expectations for interpretability and user experience in research reporting.

# Reflection and Ethical Considerations
The data used in this replication come from an ethically approved project (approved by the Ethics Committee of the Canton of Vaud, Switzerland, No. 2020-02474). The original research team ensured participants’ informed rights and autonomy through appropriate procedures in recruitment, compensation, and informed consent. In this replication, I also followed ethical standards by using only public data, avoiding access to raw sensitive scores, and conducting analyses strictly based on the original cut-off values.

In reflection, we believe that if the original study had provided more details on scale scoring (e.g., CES-D item scores and processing logic), it would improve the transparency and accuracy of cut-off determinations. During preprocessing, the original study excluded non-binary participants (n = 6). While this aligns with conventional modeling, it raises questions about inclusivity. Future research could consider alternative handling methods for rare categories (e.g., category merging, small-sample modeling, or weighted estimates) to enhance representativeness.

In addition, the current models are all main-effect models. Future studies could explore interaction effects, multiverse analysis, or multilevel modeling to better capture complex relationships and improve explanatory power.

# References

# Appendix A.
```{r appendix-table1, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
final_table1 %>%
  kable(
    caption = "Full descriptive statistics for all categorical variables (replication) (\\#tab:table2)",
    col.names = c("Variable", "Mean (SD)", "Percent")
  ) %>%
  kable_styling(full_width = TRUE, font_size = 11)
```
```{r appendix-table2, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}

# Render it into a large table and insert group_rows between each outcome group
kbl(final_table2 %>% select(-outcome),
    booktabs = TRUE,
    caption = "Regression results by outcome (replication) (Table \\#tab:table3)",
    col.names = c("Predictor", "β", "SE", "η²", "F", "R²"),
    digits = c(NA, 2, 2, 2, 2, 2)
  ) %>%
  # Group by outcome and insert titles
  group_rows(
    "CES-D (Depressive symptoms)",
    1,
    sum(data_for_kable$outcome == "cesd")
  ) %>%
  group_rows(
    "STAI-T (Anxiety)",
    sum(data_for_kable$outcome == "cesd") + 1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t"))
  ) %>%
  group_rows(
    "MBI-EX (Emotional exhaustion)",
    sum(data_for_kable$outcome %in% c("cesd","stai_t")) + 1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex"))
  ) %>%
  group_rows(
    "MBI-CY (Cynicism)",
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex")) + 1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy"))
  ) %>%
  group_rows(
    "MBI-EA (Academic efficacy)",
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy")) + 1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea"))
  ) %>%
  group_rows(
    "JSPE-S",
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea")) + 1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe"))
  ) %>%
  group_rows(
    "QCAE-Cognitive",
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe"))+1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe","qcae_cog"))
  ) %>%
  group_rows(
    "QCAE-Affective",
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe","qcae_cog"))+1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe","qcae_cog","qcae_aff"))
  ) %>%
  group_rows(
    "AMSP",
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe","qcae_cog","qcae_aff"))+1,
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe","qcae_cog","qcae_aff","amsp"))
  ) %>%
  group_rows(
    "GERT-S",
    sum(data_for_kable$outcome %in% c("cesd","stai_t","mbi_ex","mbi_cy","mbi_ea","jspe","qcae_cog","qcae_aff","amsp"))+1,
    nrow(data_for_kable)
  ) %>%
  kable_styling(
    latex_options = c("hold_position", "repeat_header"),
    full_width = FALSE,
    font_size = 11,
    position = "center"
  )
```
```{r appendix-table3, echo=FALSE, results='asis'}
table3_appendix <- final_table3 %>%
  rename(
    Empathy       = empathy,
    Outcome       = outcome,
    Beta          = estimate,
    `p stars`     = p_stars,
    SE            = std.error,
    `η² (partial)`= eta2,
    `F statistic` = F_stat,
    `R²`          = R2
  ) %>%
  mutate(
    Empathy = recode(Empathy,
      jspe      = "JSPE-S",
      qcae_cog  = "QCAE-Cognitive",
      qcae_aff  = "QCAE-Affective",
      amsp      = "AMSP",
      erec_mean = "GERT-S"
    ),
    Outcome = recode(Outcome,
      cesd    = "Depressive symptoms",
      stai_t  = "Anxiety",
      mbi_ex  = "Emotional exhaustion",
      mbi_cy  = "Cynicism",
      mbi_ea  = "Academic efficacy"
    )
  )

kable(
  table3_appendix,
  booktabs     = TRUE,
  longtable    = TRUE,
  caption      = "Relationship between empathy, mental health, and burnout (replication) (\\#tab:table4).",
  align        = c("l", "l", "r", "l", "r", "r", "r", "r"),
  digits       = c(0, 0, 2, 0, 2, 2, 2, 2)  
) %>%
  kable_styling(
    latex_options = c("repeat_header", "hold_position", "striped"),
    full_width    = FALSE
  )
```
